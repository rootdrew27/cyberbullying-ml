{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqnBXJ1QrBHQ",
        "outputId": "20337e72-8778-4654-a01f-e6ec32690983"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LXB96TNwrJaA"
      },
      "outputs": [],
      "source": [
        "#@title Imports and Installs\n",
        "# !pip install xgboost\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import re\n",
        "\n",
        "from scipy.stats.distributions import uniform, randint\n",
        "import sys\n",
        "\n",
        "import sklearn.model_selection\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import time\n",
        "\n",
        "import xgboost as xgboost\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCfE8WM6yc8I"
      },
      "outputs": [],
      "source": [
        "cleanDataPath = '/content/drive/MyDrive/UWEC/ML Research w Dr. Vanamala/Data/bullying_light_clean_data.csv'\n",
        "cleanDataPath2 = '/content/drive/MyDrive/UWEC/ML Research w Dr. Vanamala/Data/hatespeech_light_clean_data.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4qYuRKPrLYj"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(cleanDataPath)\n",
        "df2 = pd.read_csv(cleanDataPath2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpIR8rPs70wo"
      },
      "outputs": [],
      "source": [
        "df.dropna(axis=0, inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "df2.dropna(axis=0, inplace=True)\n",
        "df2.drop_duplicates(inplace=True)\n",
        "df2.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6b01HHQrlTn"
      },
      "outputs": [],
      "source": [
        "# 0 - hate_speech, 1 - offensive_language, 2 - neither"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-ppXw5LE3GI",
        "outputId": "2100920d-20b7-4631-b8e5-2cc2b04d570f"
      },
      "outputs": [],
      "source": [
        "df.cyberbullying_type.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkW-7Ftv6MUd",
        "outputId": "805120a4-69e7-4f00-a5fa-ba6023a24d32"
      },
      "outputs": [],
      "source": [
        "undersample_value = min(df.cyberbullying_type.value_counts())\n",
        "undersample_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hz3sc51dBzJl"
      },
      "outputs": [],
      "source": [
        "# split classes\n",
        "religion = df[df['cyberbullying_type'] == 'religion']\n",
        "age = df[df['cyberbullying_type'] == 'age']\n",
        "gender = df[df['cyberbullying_type'] == 'gender']\n",
        "ethnicity = df[df['cyberbullying_type'] == 'ethnicity']\n",
        "other_cyberbullying = df[df['cyberbullying_type'] == 'other_cyberbullying']\n",
        "not_cyberbullying = df[df['cyberbullying_type'] == 'not_cyberbullying']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jQRW_l6EuoU"
      },
      "outputs": [],
      "source": [
        "religion_us = religion.sample(undersample_value)\n",
        "age_us = age.sample(undersample_value)\n",
        "gender_us = gender.sample(undersample_value)\n",
        "ethnicity_us = ethnicity.sample(undersample_value)\n",
        "other_cyberbullying_us = other_cyberbullying.sample(undersample_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsDo5nO1FG1H"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([religion_us, age_us, gender_us, ethnicity_us, other_cyberbullying_us, not_cyberbullying], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KT7LE9FStlx5",
        "outputId": "83b50319-8ff4-441b-d227-bfb618c68442"
      },
      "outputs": [],
      "source": [
        "df.cyberbullying_type.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6lrUdAEFhrx"
      },
      "outputs": [],
      "source": [
        "# convert str labels to integers\n",
        "df['cyberbullying_type'] = df['cyberbullying_type'].replace({\n",
        "        'religion': 0,\n",
        "        'age': 1,\n",
        "        'gender': 2,\n",
        "        'ethnicity': 3,\n",
        "        'other_cyberbullying': 4,\n",
        "        'not_cyberbullying': 5\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krvtFF8zFJyU"
      },
      "outputs": [],
      "source": [
        "# Bag of Words\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(df.tweet_text)\n",
        "\n",
        "# SBERT\n",
        "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "# X = model.encode(df.tweet_text)\n",
        "\n",
        "# TF-IDF\n",
        "# vectorizer = TfidfVectorizer()\n",
        "# X = vectorizer.fit_transform(df.tweet_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL3_LZ4Xp3Cp"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7EvJvRhGY9c"
      },
      "outputs": [],
      "source": [
        "# split data\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, df.cyberbullying_type, test_size=0.2, random_state=115)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veOpe9_f-5ws"
      },
      "outputs": [],
      "source": [
        "# control overfitting\n",
        "# https://xgboost.readthedocs.io/en/stable/tutorials/param_tuning.html\n",
        "\n",
        "# parameters to mitigate overfitting\n",
        "ptmo = {\n",
        "    'max_depth': 4,\n",
        "    'learning_rate': 0.02,\n",
        "    'n_estimators': 600,\n",
        "    'gamma': 1.0,\n",
        "    'min_child_weight': 1.5,\n",
        "    'subsample': 0.9, # percent of training data to use\n",
        "    'colsample_bytree': 0.8,\n",
        "    'eval_metric': 'auc'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "BoowSYrQJB52",
        "outputId": "54567a3f-e182-482c-c167-9895039b8400"
      },
      "outputs": [],
      "source": [
        "xgb = XGBClassifier(objective='multi:softmax', random_state=115)\n",
        "# fit model\n",
        "xgb.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MU2DpPReP_WN"
      },
      "outputs": [],
      "source": [
        "preds = xgb.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSbSNLaPQzzB"
      },
      "outputs": [],
      "source": [
        "model1Results = 'Model 1 Accuracy : {0:0.4f}\\n'. format(accuracy_score(y_test, preds)) + '\\nModel 1 Classification Report:\\n' + classification_report(y_test, preds) + '\\n\\n'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UrO0UmDQ4ir",
        "outputId": "3b3a2d89-0941-4575-824b-2a5e7231faff"
      },
      "outputs": [],
      "source": [
        "print(model1Results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDHDlzgmSNZN"
      },
      "outputs": [],
      "source": [
        "# class 3 - not many other classes predicted to be class 3 but a notable amount of the true class 3 were missed (ie 80% recall)\n",
        "# class 4 - Many other classes were predicted to be class 4 but 80% of class4 was correctly predicited as class4\n",
        "# class 5 - Many other classes were predicted to be class 5 and ~50% of class5 was not properly predicted to be class5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x9WpaqodYb9"
      },
      "outputs": [],
      "source": [
        "# TODO: Setup up Grid Search to find optimal params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RAur5iVheEL"
      },
      "source": [
        "Test Model(s) on other dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Tf5c9NvhMV5"
      },
      "outputs": [],
      "source": [
        "# 0 - hate_speech, 1 - offensive_language, 2 - neither\n",
        "df2['class'] = df2['class'].apply(lambda x: x if x == 0 else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqNgf6B1jNHN",
        "outputId": "3c1e53ef-eb15-4292-8174-ffa1e0c56c70"
      },
      "outputs": [],
      "source": [
        "df2.value_counts('class')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBOP2t9DjiQ_"
      },
      "outputs": [],
      "source": [
        "x, y = df2['tweet'], df2['class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSzGs3gejpvi"
      },
      "outputs": [],
      "source": [
        "preds = xgb.predict(vectorizer.transform(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAZmaLl7khRG"
      },
      "outputs": [],
      "source": [
        "# convert preds to labels that are conducive with the new datasets labels\n",
        "preds = [1 if x in [5] else 0 for x in preds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUycgCVOkttg"
      },
      "outputs": [],
      "source": [
        "model1Results = 'Model 1 Accuracy : {0:0.4f}\\n'. format(accuracy_score(y, preds)) + '\\nModel 1 Classification Report:\\n' + classification_report(y, preds) + '\\n\\n'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfKD9Xk8kzGU",
        "outputId": "638f953e-677d-48c1-ae0e-a6536143199b"
      },
      "outputs": [],
      "source": [
        "print(model1Results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oUPN64ulOIE"
      },
      "outputs": [],
      "source": [
        "# an inital test on this dataset shows that the model is heavily biased towards cyberbullying (see precision of class 0)\n",
        "# to account for this, we should"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eASlDj4i-Bc1"
      },
      "outputs": [],
      "source": [
        "# Run further tests.\n",
        "# Ajdust the test sizes to reflect the training class distribution (NOTE: this is likely NOT consistent with real world data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd09ojdPmyAR",
        "outputId": "6670f091-e614-45e0-a24e-eb7f1bfd7e17"
      },
      "outputs": [],
      "source": [
        "# x, y = df2['tweet'], df2['class']\n",
        "# preds = xgb.predict(vectorizer.transform(x))\n",
        "# preds = [1 if x in [3, 4, 5] else 0 for x in preds]\n",
        "# print('Model 1 Accuracy : {0:0.4f}\\n'. format(accuracy_score(y, preds)) + '\\nModel 1 Classification Report:\\n' + classification_report(y, preds) + '\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMgZBWabr1hC"
      },
      "source": [
        "#Test\n",
        "---\n",
        "The following test serves to evaluate the generalizability of XGBoost when trained upon the cyberbullying dataset curated in https://people.cs.vt.edu/ctlu/Publication/2020/IEEE-BD-SOSNet-Wang.pdf\n",
        "\n",
        "The test data is from https://arxiv.org/pdf/1703.04009\n",
        "\n",
        "1. Balance the original dataset such that each \"cyberbullying\" class has 5632 entrys.\n",
        "\n",
        "2. Also balance the test dataset such that the split is 50/50.\n",
        "\n",
        "3. Use the remaining \"not cyberbullying\" from the test set for model training. Thus the training data will match the distribution of the test data (50/50 split between \"cyberbullying\" and \"not cyberbullying\")\n",
        "\n",
        "(This is not necessarily a realistic representation of real-world data but it is a good initial test for the model)\n",
        "\n",
        "4. Try all encoding types and try training the model with 2 classes (rather than 6).**bold text**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "cleanDataPath = 'data/bullying_light_clean_data.csv'\n",
        "cleanDataPath2 = 'data/hatespeech_light_clean_data.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l8ElIQaYvrTD"
      },
      "outputs": [],
      "source": [
        "# Read in the data\n",
        "df = pd.read_csv(cleanDataPath)\n",
        "df2 = pd.read_csv(cleanDataPath2)\n",
        "\n",
        "df.dropna(axis=0, inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "df2.dropna(axis=0, inplace=True)\n",
        "df2.drop_duplicates(inplace=True)\n",
        "df2.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XxhNpEV_zbPZ"
      },
      "outputs": [],
      "source": [
        "# split classes\n",
        "religion = df[df['cyberbullying_type'] == 'religion']\n",
        "age = df[df['cyberbullying_type'] == 'age']\n",
        "gender = df[df['cyberbullying_type'] == 'gender']\n",
        "ethnicity = df[df['cyberbullying_type'] == 'ethnicity']\n",
        "other_cyberbullying = df[df['cyberbullying_type'] == 'other_cyberbullying']\n",
        "not_cyberbullying = df[df['cyberbullying_type'] == 'not_cyberbullying']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2JW82PPt0F2G"
      },
      "outputs": [],
      "source": [
        "undersample_value = 5150 # (20731 - 1219 + 6238) / 5\n",
        "\n",
        "religion_us = religion.sample(undersample_value)\n",
        "age_us = age.sample(undersample_value)\n",
        "gender_us = gender.sample(undersample_value)\n",
        "ethnicity_us = ethnicity.sample(undersample_value)\n",
        "other_cyberbullying_us = other_cyberbullying.sample(undersample_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cQZpu9VU0K9I"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([religion_us, age_us, gender_us, ethnicity_us, other_cyberbullying_us, not_cyberbullying], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KgTVSQ2u6N2s"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\rooty\\AppData\\Local\\Temp\\ipykernel_8660\\1080874665.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['cyberbullying_type'] = df['cyberbullying_type'].replace({\n"
          ]
        }
      ],
      "source": [
        "# convert str labels to integers\n",
        "df['cyberbullying_type'] = df['cyberbullying_type'].replace({\n",
        "        'religion': 0,\n",
        "        'age': 1,\n",
        "        'gender': 2,\n",
        "        'ethnicity': 3,\n",
        "        'other_cyberbullying': 4,\n",
        "        'not_cyberbullying': 5\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnOaxTUZ8RBv",
        "outputId": "42c9508c-f778-46a5-c15e-b43957a1ac81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "cyberbullying_type\n",
              "5    6238\n",
              "0    5150\n",
              "1    5150\n",
              "2    5150\n",
              "3    5150\n",
              "4    5150\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.cyberbullying_type.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "31988"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mVUrGMp4071p"
      },
      "outputs": [],
      "source": [
        "# 0 - hate_speech, 1 - offensive_language, 2 - neither\n",
        "df2['class'] = df2['class'].apply(lambda x: x if x == 0 else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDhLZpfV8ZDQ",
        "outputId": "2aa1a8a3-c9fd-421b-db98-226bc1454c56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "class\n",
              "1    20731\n",
              "0     1219\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2['class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bRUWGao0-_TB"
      },
      "outputs": [],
      "source": [
        "df2 = df2.sample(frac=1, random_state=115) # shuffle the data\n",
        "\n",
        "# split by class\n",
        "not_cyberbullying = df2[df2['class'] == 1]\n",
        "cyberbullying = df2[df2['class'] == 0]\n",
        "\n",
        "additional_not_cyberbullying = 19512 # 20731 - 1219\n",
        "\n",
        "tmp = not_cyberbullying.iloc[:additional_not_cyberbullying] # 19512\n",
        "not_cyberbullying = not_cyberbullying.iloc[additional_not_cyberbullying:] # 1219\n",
        "\n",
        "# add the additional 'not cyberbullying' data to the training dataset\n",
        "tmp.rename(columns={'tweet': 'tweet_text', 'class': 'cyberbullying_type'}, inplace=True)\n",
        "tmp['cyberbullying_type'] = 5\n",
        "df = pd.concat([df, tmp])\n",
        "\n",
        "df2 = pd.concat([not_cyberbullying, cyberbullying])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NWSOEEtE-o_"
      },
      "source": [
        "- Sanity Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDkARYw89ZJk",
        "outputId": "f5632f30-882c-4f35-fa5b-1092d996ef08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "cyberbullying_type\n",
              "0     5150\n",
              "1     5150\n",
              "2     5150\n",
              "3     5150\n",
              "4     5150\n",
              "5    25750\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.cyberbullying_type.value_counts(sort=False) # 50/50 split between cyberbullying and not cyberbullying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "51500"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkzUz08WE00m",
        "outputId": "4a65fa10-fc21-4f2b-c2cb-ef90b140f861"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "class\n",
              "1    1219\n",
              "0    1219\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2['class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "a5OEYqa56JLv"
      },
      "outputs": [],
      "source": [
        "x, y = df2['tweet'], df2['class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "mHnxrPvJbvPI"
      },
      "outputs": [],
      "source": [
        "# Split training data\n",
        "X_train, X_val, Y_train, Y_val = sklearn.model_selection.train_test_split(df.tweet_text, df.cyberbullying_type, test_size=0.2, random_state=115)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "WIf5gsjU6R0l"
      },
      "outputs": [],
      "source": [
        "# Bag of Words\n",
        "vectorizer = CountVectorizer()\n",
        "x_train = vectorizer.fit_transform(X_train)\n",
        "X_val = vectorizer.transform(X_val)\n",
        "\n",
        "# SBERT\n",
        "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "# X = model.encode(df.tweet_text)\n",
        "\n",
        "# TF-IDF\n",
        "# vectorizer = TfidfVectorizer()\n",
        "# X = vectorizer.fit_transform(df.tweet_text)\n",
        "\n",
        "y_train = Y_train\n",
        "Y_val = Y_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W5rpLVov2Rt"
      },
      "outputs": [],
      "source": [
        "# Justification for random search : https://dl.acm.org/doi/pdf/10.5555/2188385.2188395"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnSNY1aax1g4"
      },
      "outputs": [],
      "source": [
        "def tune_hyperparameters(base_model, parameters, n_iter, kfold, X, Y, X_val=None, Y_val=None, SEED=115):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Arrange data into folds with approx equal proportion of classes within each fold\n",
        "    k = KFold(kfold)\n",
        "\n",
        "    optimal_model = RandomizedSearchCV(\n",
        "                            base_model,\n",
        "                            param_distributions=parameters,\n",
        "                            n_iter=n_iter,\n",
        "                            cv=k,\n",
        "                            random_state=SEED,\n",
        "                            scoring='neg_log_loss',\n",
        "                            n_jobs=1,\n",
        "                            verbose=3,\n",
        "                            error_score='raise'\n",
        "                            )\n",
        "\n",
        "    optimal_model.fit(X, Y)#,eval_set=zip(X_val, Y_val))\n",
        "\n",
        "    stop_time = time.time()\n",
        "\n",
        "    scores = cross_val_score(optimal_model, X, Y, cv=k, scoring=\"accuracy\")\n",
        "\n",
        "    print(\"Elapsed Time:\", time.strftime(\"%H:%M:%S\", time.gmtime(stop_time - start_time)))\n",
        "    print(\"====================\")\n",
        "    print(\"Cross Val Mean: {:.3f}, Cross Val Stdev: {:.3f}\".format(scores.mean(), scores.std()))\n",
        "    print(\"Best Score: {:.3f}\".format(optimal_model.best_score_))\n",
        "    print(\"Best Parameters: {}\".format(optimal_model.best_params_))\n",
        "\n",
        "    return optimal_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UniCYALlDw6i"
      },
      "outputs": [],
      "source": [
        "# Parameter Searching Guide : https://www.kaggle.com/code/willkoehrsen/intro-to-model-tuning-grid-and-random-search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "N_FOLDS = 2\n",
        "\n",
        "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=115)\n",
        "\n",
        "def objective(hyperparameters, iteration):\n",
        "  \"\"\"Objective function for grid and random search. Returns\n",
        "      the cross validation score from a set of hyperparameters.\"\"\"\n",
        "   \n",
        "  cv_results = cross_val_score(m, x_train, y_train, cv=skf) # NOTE : use xgb's internal scoring method\n",
        "  \n",
        "  return [cv_results.mean(), cv_results.std(), hyperparameters, iteration]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://www.kaggle.com/code/willkoehrsen/intro-to-model-tuning-grid-and-random-search#Random-Search\n",
        "\n",
        "import random\n",
        "\n",
        "def random_search(param_grid, objective, max_evals=10):\n",
        "    \"\"\"Random search for hyperparameter optimization\"\"\"\n",
        "    \n",
        "    # Dataframe for results\n",
        "    results = pd.DataFrame(columns = ['score (mean)', 'score (std)', 'params', 'iteration'],\n",
        "                                  index = list(range(max_evals)))\n",
        "    \n",
        "    # Keep searching until reach max evaluations\n",
        "    for i in range(max_evals):\n",
        "        \n",
        "        # Choose random hyperparameters\n",
        "        hyperparameters = {}\n",
        "        for k,v in param_grid.items():\n",
        "            v = random.sample(v,1)[0] if isinstance(v, (list, tuple)) else v.rvs(1)[0]\n",
        "            hyperparameters[k] = v        \n",
        "\n",
        "        start_time = time.time()\n",
        "        # Evaluate randomly selected hyperparameters\n",
        "        eval_results = objective(hyperparameters, i)\n",
        "        \n",
        "        stop_time = time.time()\n",
        "                \n",
        "        results.loc[i, :] = eval_results        \n",
        "        \n",
        "        print(\"Elapsed Time: {i} fd {time.strftime(\"%H:%M:%S\", time.gmtime(stop_time - start_time))}\")\n",
        "    \n",
        "    # Sort with best score on top\n",
        "    results.sort_values('score (mean)', ascending=False, inplace=True)\n",
        "    results.reset_index(inplace = True, drop=True)\n",
        "    return results "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n",
            "\n",
            "Input Type: <class 'scipy.sparse._csr.csr_matrix'>\n",
            "\n",
            "Input Sample:\n",
            "12189     twitter tipped its cap to say farewellcaptain...\n",
            "15842     when you give all ya hoes up for that one gir...\n",
            "Name: tweet, dtype: object\n",
            "\n",
            "Target Typep: <class 'pandas.core.series.Series'>\n",
            "\n",
            "Target Sample:\n",
            "12189    1\n",
            "15842    1\n",
            "Name: class, dtype: int64\n",
            "\n",
            "Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=None, device='cpu', early_stopping_rounds=None,\n",
            "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
            "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=None, n_jobs=-1, num_class=6,\n",
            "              num_parallel_tree=None, ...)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# stats.uniform(0.5, 0.9)\n",
        "\n",
        "parameters = {\n",
        "    'booster'              : ['gbtree','dart'],\n",
        "    'n_estimators'         : [100, 200, 300, 400, 500, 600],\n",
        "    'learning_rate'        : uniform(0.0001, 0.1),\n",
        "    # 'max_depth'            : randint(3, 100),\n",
        "    # 'min_child_weight'     : randint(1, 50),\n",
        "    # 'subsample'            : uniform(sys.float_info.min, 1),\n",
        "    # 'colsample_bytree'     : uniform(0,1),\n",
        "    # 'colsample_bylevel'    : uniform(0,1),\n",
        "    # 'colsample_bynode'     : uniform(0,1),\n",
        "    # 'n_estimators'         : [100,200,300,400,500,600],\n",
        "    # 'alpha'                : uniform(0,10),\n",
        "    # 'lambda'               : uniform(0,10),\n",
        "    # 'gamma'                : uniform(0, 100),\n",
        "    # 'eta'                  : uniform(0,1)\n",
        "}\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "m = XGBClassifier(objective='multi:softmax', num_class=6, device=device, n_jobs=-1, verbosity=1, random_state=115)\n",
        "\n",
        "# Verify that the following are properly defined\n",
        "print(f'Device: {device}\\n')\n",
        "print(f'Input Type: {type(x_train)}\\n\\nInput Sample:\\n{x[:2]}\\n')\n",
        "print(f'Target Typep: {type(y_train)}\\n\\nTarget Sample:\\n{y[:2]}\\n')\n",
        "print(f'Model: {m}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parameters.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed Time: 00:00:10\n",
            "Elapsed Time: 00:00:10\n"
          ]
        }
      ],
      "source": [
        "result = random_search(parameters, objective, max_evals=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score (mean)</th>\n",
              "      <th>score (std)</th>\n",
              "      <th>params</th>\n",
              "      <th>iteration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.868495</td>\n",
              "      <td>0.000534</td>\n",
              "      <td>{'booster': 'gbtree', 'n_estimators': 300, 'le...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.868495</td>\n",
              "      <td>0.000534</td>\n",
              "      <td>{'booster': 'gbtree', 'n_estimators': 500, 'le...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  score (mean) score (std)                                             params  \\\n",
              "0     0.868495    0.000534  {'booster': 'gbtree', 'n_estimators': 300, 'le...   \n",
              "1     0.868495    0.000534  {'booster': 'gbtree', 'n_estimators': 500, 'le...   \n",
              "\n",
              "  iteration  \n",
              "0         0  \n",
              "1         1  "
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "d = randint(1,5)\n",
        "d.rvs(1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "u = uniform(0,1)\n",
        "u.rvs(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results.std()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "results = pd.DataFrame(columns = ['score (mean)', 'score (std)', 'params'], index = list(range(10)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "results.loc[0,:] = [1,2,3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score (mean)</th>\n",
              "      <th>score (std)</th>\n",
              "      <th>params</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  score (mean) score (std) params\n",
              "0            1           2      3\n",
              "1          NaN         NaN    NaN\n",
              "2          NaN         NaN    NaN\n",
              "3          NaN         NaN    NaN\n",
              "4          NaN         NaN    NaN\n",
              "5          NaN         NaN    NaN\n",
              "6          NaN         NaN    NaN\n",
              "7          NaN         NaN    NaN\n",
              "8          NaN         NaN    NaN\n",
              "9          NaN         NaN    NaN"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
